{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999d82ab-9d0d-4496-900d-c9d1836b1c9f",
   "metadata": {},
   "source": [
    "# Define BiKA Linear and Conv2d Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfd9c06-5604-49a2-9fdc-4217b483a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d21be32-53be-49ff-99af-d7a5388e2afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output during inference: tensor([ 1., -1., -1.,  1.], grad_fn=<CustomSignFunctionBackward>)\n",
      "Gradient during training: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "class CustomSignFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Save the input for backward computation\n",
    "        ctx.save_for_backward(input)\n",
    "        # Output +1 for input > 0, else -1 (including for input == 0)\n",
    "        return torch.where(input > 0, torch.tensor(1.0, device=input.device), torch.tensor(-1.0, device=input.device))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Retrieve the input saved in the forward pass\n",
    "        input, = ctx.saved_tensors\n",
    "        # Gradient of the input is the same as the gradient output (STE)\n",
    "        grad_input = grad_output.clone()\n",
    "        # Pass the gradient only where input was non-zero, otherwise set it to 0\n",
    "        grad_input[input.abs() > 0] = grad_output[input.abs() > 0]\n",
    "        return grad_input\n",
    "\n",
    "# Wrapper class for convenience\n",
    "class CustomSignActivation(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomSignActivation, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return CustomSignFunction.apply(input)\n",
    "\n",
    "# Example usage:\n",
    "sign_activation = CustomSignActivation()\n",
    "\n",
    "# Test the forward pass\n",
    "x = torch.tensor([2.0, -3.0, 0.0, 1.5], requires_grad=True)\n",
    "output = sign_activation(x)\n",
    "print(\"Output during inference:\", output)\n",
    "\n",
    "# Test the backward pass (gradient computation during training)\n",
    "loss = output.sum()  # Just an example loss\n",
    "loss.backward()\n",
    "print(\"Gradient during training:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c04babe-edac-4d60-b458-2550bdddc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiKALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(BiKALinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.sign = CustomSignActivation()\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expand the input to match the bias shape for broadcasting\n",
    "        # x is of shape (batch_size, in_features)\n",
    "        # Expand bias matrix to (batch_size, out_features, in_features)\n",
    "        x = x.unsqueeze(1) + self.bias.unsqueeze(0)\n",
    "        \n",
    "        # Perform element-wise multiplication with weights\n",
    "        x = x * self.weight.unsqueeze(0)\n",
    "        \n",
    "        # Apply sign function: -1 for negative and 0, 1 for positive\n",
    "        x = self.sign(x)\n",
    "        \n",
    "        # Sum the thresholded products along the input features dimension\n",
    "        x = torch.sum(x, dim=-1) \n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "bika_linear = BiKALinear(in_features=2, out_features=3)\n",
    "input_tensor  = torch.randn(3, 2)  # Batch of 3, 10 input features each\n",
    "output_tensor = bika_linear(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91df2d1-eae3-44cb-9150-c0176ee97367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiKAConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1):\n",
    "        super(BiKAConv2D, self).__init__()\n",
    "        # Define weights for convolution\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        )\n",
    "        # Define an individual bias for each weight in the kernel\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        )\n",
    "        self.sign = CustomSignActivation()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):   \n",
    "        batch_size, in_channels, height, width = x.shape\n",
    "        out_height = int((height + 2*self.padding-self.dilation*(self.kernel_size-1)-1)/self.stride+1)\n",
    "        out_width = int((width + 2*self.padding-self.dilation*(self.kernel_size-1)-1)/self.stride+1)\n",
    "        unfold_length = out_height*out_width\n",
    "        \n",
    "        # Add the bias to each activation before multiplying by the weight\n",
    "        # Equivalent to computing w * (a + b) for each kernel position\n",
    "        modified_input = F.unfold(x, kernel_size=self.weight.shape[2:], stride=self.stride, padding=self.padding)\n",
    "        modified_input = modified_input.view(x.shape[0], x.shape[1], self.weight.shape[2], self.weight.shape[3], -1).unsqueeze(1)\n",
    "        modified_bias = self.bias.unsqueeze(-1).unsqueeze(0)\n",
    "        modified_input = modified_input + modified_bias\n",
    "        modified_input = modified_input.view(x.shape[0], -1, modified_input.shape[-1])\n",
    "        \n",
    "        # Perform the convolution with the modified input\n",
    "        modified_weight = self.weight.view(-1).unsqueeze(0).unsqueeze(2)\n",
    "        output=modified_input * modified_weight\n",
    "        \n",
    "        # Apply sign function: -1 for negative and 0, 1 for positive\n",
    "        output = self.sign(output)\n",
    "        \n",
    "        # Sum the thresholded products along the input features dimension\n",
    "        output = output.view(batch_size, self.out_channels, in_channels*self.kernel_size*self.kernel_size,unfold_length)\n",
    "        output = output.sum(dim=2) \n",
    "        output = output.view(batch_size, self.out_channels, out_height, out_width)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "bika_conv = BiKAConv2D(in_channels=2, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "input_tensor  = torch.arange(0, 36, dtype=torch.float32).reshape(2,2,3,3)\n",
    "output_tensor = bika_conv(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a278449-8168-44ac-a20d-ded07c23b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.]],\n",
      "\n",
      "         [[ 9., 10., 11.],\n",
      "          [12., 13., 14.],\n",
      "          [15., 16., 17.]]],\n",
      "\n",
      "\n",
      "        [[[18., 19., 20.],\n",
      "          [21., 22., 23.],\n",
      "          [24., 25., 26.]],\n",
      "\n",
      "         [[27., 28., 29.],\n",
      "          [30., 31., 32.],\n",
      "          [33., 34., 35.]]]])\n",
      "torch.Size([2, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor)\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc688e0-b2e8-4f15-8ffa-3e826e902de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.,  0.,  6.],\n",
      "          [ 0., -4.,  2.],\n",
      "          [ 0.,  0.,  4.]],\n",
      "\n",
      "         [[-6., -4.,  2.],\n",
      "          [-6., -2.,  4.],\n",
      "          [-2.,  0.,  2.]],\n",
      "\n",
      "         [[ 2.,  2.,  4.],\n",
      "          [ 6.,  6.,  4.],\n",
      "          [ 8.,  8.,  4.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  6.],\n",
      "          [-2., -4.,  2.],\n",
      "          [ 0.,  0.,  4.]],\n",
      "\n",
      "         [[-6., -4.,  2.],\n",
      "          [-6., -2.,  4.],\n",
      "          [-2.,  0.,  2.]],\n",
      "\n",
      "         [[ 4.,  4.,  4.],\n",
      "          [ 6.,  4.,  2.],\n",
      "          [ 8.,  8.,  4.]]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor)\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320da33-9040-4dc0-b03e-9cbca4e4c6fb",
   "metadata": {},
   "source": [
    "# Try Tiny BiKA with MNIST and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b745b342-d660-45e2-b77d-ec77eb986dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9684a2a-dc40-47cc-82bb-d24e162880cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.MNIST('./data/', \n",
    "                                        train=True, download=True,\n",
    "                                        transform=torchvision.transforms.Compose\n",
    "                                        ([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            #torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                            torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "                                        ]))\n",
    "data_test = torchvision.datasets.MNIST('./data/', \n",
    "                                       train=False, download=True,\n",
    "                                       transform=torchvision.transforms.Compose\n",
    "                                       ([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            #torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                            torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "                                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9835430b-f7cd-4436-8759-aed7f62aa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size_train = 512\n",
    "batch_size_test = 1000\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size=batch_size_train, \n",
    "                                                shuffle=True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size=batch_size_test, \n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7909363-f624-44e6-ac52-55907a72fd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3725, -0.0745,\n",
      "         -0.0745, -0.0745, -0.0745,  0.2078,  0.9922,  1.0000,  0.9922,  0.9922,\n",
      "          0.9922,  0.0588, -0.3020, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000,  0.8431,  0.8353,  0.8353,  0.8353,  0.9373,  0.9843,\n",
      "          0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "          0.9843,  0.9843,  0.9451,  0.0667, -0.7098, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000,  0.9922,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "          0.9843,  0.9843,  0.9843,  0.9843,  0.5451,  0.7176,  0.3882,  0.3882,\n",
      "          0.6314,  0.9843,  0.9843,  0.9843,  0.7020, -0.7255, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -0.0196,  0.5529,  0.2314, -0.5216, -0.5216, -0.5216,\n",
      "         -0.5216, -0.5216, -0.5216, -0.5216, -0.8667, -0.7412, -1.0000, -1.0000,\n",
      "         -0.8039, -0.5216,  0.4275,  0.9843,  0.9843,  0.7255, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -0.5059,  0.9843,  0.9843,  0.9843, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -0.5059,  0.9843,  0.9843,  0.9294, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -0.5059,  0.9843,  0.9843, -0.0902, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -0.5059,  0.9843,  0.9843, -0.0902, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  0.4510,  0.9843,  0.9843, -0.0902, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -0.8196,  0.6784,  0.9843,  0.5608, -0.8275, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000,  0.4353,  0.9843,  0.9843, -0.2471, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000,  0.7255,  0.9843,  0.9529, -0.3333, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -0.9765,  0.7333,  0.9843,  0.6314, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -0.1843,  0.9843,  0.9843, -0.4118, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6000,\n",
      "          0.8745,  0.9843,  0.5216, -0.9686, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.0196,\n",
      "          0.9843,  0.9843,  0.1451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6863,  0.7725,\n",
      "          0.9843,  0.8275, -0.6784, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9608,  0.2706,  0.9843,\n",
      "          0.9843,  0.4431, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7804,  0.9843,  0.9843,\n",
      "          0.9843,  0.9294, -0.6078, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7804,  0.9843,  0.9843,\n",
      "          0.9843, -0.2392, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(data_loader_train)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data[0][0])\n",
    "example_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6777605-73e4-4501-9e27-105529f12443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f9203c-d0f5-4f31-8cdc-7a35479b312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=3\n",
    "\n",
    "in_channels0=1\n",
    "out_channels0=16 \n",
    "\n",
    "in_channels1=out_channels0\n",
    "out_channels1=16\n",
    "\n",
    "input_size = 7*7*out_channels1 \n",
    "hidden0 = 1024   \n",
    "num_classes = 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75c84807-0af8-4687-aa09-a9adf531376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class BiKA_MNIST(Module):\n",
    "    def __init__(self):\n",
    "        super(BiKA_MNIST, self).__init__()\n",
    "        \n",
    "        self.conv0_0 = BiKAConv2D(in_channels=in_channels0, out_channels=out_channels0, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        self.conv0_1 = BiKAConv2D(in_channels=out_channels0, out_channels=out_channels0, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        \n",
    "        self.pool0 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv1_0 = BiKAConv2D(in_channels=in_channels1, out_channels=out_channels1, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        self.conv1_1 = BiKAConv2D(in_channels=out_channels1, out_channels=out_channels1, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.fc0   = BiKALinear(in_features=input_size, out_features=hidden0)\n",
    "        \n",
    "        self.out   = BiKALinear(in_features=hidden0, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        res_in = x\n",
    "        out = self.conv0_1(self.conv0_0(x))\n",
    "        out = out + res_in\n",
    "        \n",
    "        out = self.pool0(out)\n",
    "        \n",
    "        res_in = out\n",
    "        out = self.conv1_1(self.conv1_0(out))\n",
    "        out = out + res_in\n",
    "        \n",
    "        out = self.pool1(out)\n",
    "        \n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc0(out)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "   \n",
    "model = BiKA_MNIST() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e05d87a-b13d-4326-b263-ae57d942deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        inputs, target = data\n",
    "        #inputs, target = inputs.cuda(), target.cuda()\n",
    "        inputs, target = Variable(inputs), Variable(target)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _,pred = torch.max(outputs.data,1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs,target)\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.data.numpy()) \n",
    "           \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c189b257-8dd4-403f-9477-f3aaa73bf75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            #inputs, target = inputs.cuda(), target.cuda()\n",
    "            inputs, target = Variable(inputs),Variable(target)\n",
    "            output = model(inputs)\n",
    "            #output = torch.sigmoid(output_orig)  \n",
    "            _,pred = torch.max(output,1)\n",
    "            # compare against a threshold of 0.5 to generate 0/1\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51f62d7f-96cc-4898-986c-c08d0ec9e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learn_rate = 0.0001 \n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f131821-1152-4250-88c4-d0fa02828e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49d92f84-df5e-4f67-aa9e-739ee21899f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss:   0%|                                     | 0/20 [00:37<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m t \u001b[38;5;241m=\u001b[39m trange(num_epochs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[0;32m---> 14\u001b[0m         loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         test_acc \u001b[38;5;241m=\u001b[39m test(model, data_loader_test)\n\u001b[1;32m     16\u001b[0m         t\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss = \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m test accuracy = \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(loss_epoch), test_acc))\n",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs,target)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# keep track of loss value\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.10/site-packages/torch/autograd/function.py:288\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    287\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "t = trange(num_epochs, desc=\"Training loss\", leave=True)\n",
    "\n",
    "for epoch in t:\n",
    "        loss_epoch = train(model, data_loader_train, optimizer, criterion)\n",
    "        test_acc = test(model, data_loader_test)\n",
    "        t.set_description(\"Training loss = %f test accuracy = %f\" % (np.mean(loss_epoch), test_acc))\n",
    "        t.refresh() # to show immediately the update           \n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb1e43-c022-428a-aff0-eb79465d091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f35f6-7dc8-4bd6-b949-b0f0d210584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3f45d-37cf-46d0-9257-75e762716ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, data_loader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
