{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac0e806-d6eb-4183-b62a-0368c33b9d23",
   "metadata": {},
   "source": [
    "# Define BiKA Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42cc2af-891e-488f-8a2f-9c4808a378d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a09ecd-5136-469a-952a-0e86ae3f8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output during inference: tensor([ 1., -1., -1.,  1.], grad_fn=<CustomSignFunctionBackward>)\n",
      "Gradient during training: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "class CustomSignFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Save the input for backward computation\n",
    "        ctx.save_for_backward(input)\n",
    "        # Output +1 for input > 0, else -1 (including for input == 0)\n",
    "        return torch.where(input > 0, torch.tensor(1.0, device=input.device), torch.tensor(-1.0, device=input.device))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Retrieve the input saved in the forward pass\n",
    "        input, = ctx.saved_tensors\n",
    "        # Gradient of the input is the same as the gradient output (STE)\n",
    "        grad_input = grad_output.clone()\n",
    "        # Pass the gradient only where input was non-zero, otherwise set it to 0\n",
    "        grad_input[input.abs() > 0] = grad_output[input.abs() > 0]\n",
    "        return grad_input\n",
    "\n",
    "# Wrapper class for convenience\n",
    "class CustomSignActivation(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomSignActivation, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return CustomSignFunction.apply(input)\n",
    "\n",
    "# Example usage:\n",
    "sign_activation = CustomSignActivation()\n",
    "\n",
    "# Test the forward pass\n",
    "x = torch.tensor([2.0, -3.0, 0.0, 1.5], requires_grad=True)\n",
    "output = sign_activation(x)\n",
    "print(\"Output during inference:\", output)\n",
    "\n",
    "# Test the backward pass (gradient computation during training)\n",
    "loss = output.sum()  # Just an example loss\n",
    "loss.backward()\n",
    "print(\"Gradient during training:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ab553d-22ba-4ce6-a69e-d131fb55c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiKALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, expand_factor):\n",
    "        super(BiKALinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.expand_factor = expand_factor\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features*expand_factor))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features, in_features*expand_factor))\n",
    "        self.sign = CustomSignActivation()\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.repeat_interleave(self.expand_factor, dim=1)\n",
    "        # Expand the input to match the bias shape for broadcasting\n",
    "        # x is of shape (batch_size, in_features)\n",
    "        # Expand bias matrix to (batch_size, out_features, in_features)\n",
    "        x = x.unsqueeze(1) + self.bias.unsqueeze(0)\n",
    "        \n",
    "        # Perform element-wise multiplication with weights\n",
    "        x = x * self.weight.unsqueeze(0)\n",
    "        \n",
    "        # Apply sign function: -1 for negative and 0, 1 for positive\n",
    "        x = self.sign(x)\n",
    "        \n",
    "        # Sum the thresholded products along the input features dimension\n",
    "        x = torch.sum(x, dim=-1) \n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "bika_linear = BiKALinear(in_features=2, out_features=3, expand_factor=2)\n",
    "input_tensor  = torch.randn(3, 2)  # Batch of 3, 10 input features each\n",
    "output_tensor = bika_linear(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427c2f6c-096f-4b6a-9b45-3a4379a0aa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5295,  0.1003],\n",
      "        [ 0.3280, -1.7500],\n",
      "        [ 0.3341, -0.1514]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor)\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38906c59-f428-4c2e-b4b6-65362ec34888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3400,  0.1330, -0.0959, -0.3883],\n",
      "        [ 0.4750,  0.3753, -0.3736,  0.2886],\n",
      "        [-0.1781,  0.1918,  0.3670,  0.0824]], requires_grad=True)\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(bika_linear.weight)\n",
    "print(bika_linear.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "325140eb-8269-413f-af18-5a5845eaedf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0453,  0.3788, -0.0089,  0.4016],\n",
      "        [ 0.3810,  0.2465,  0.2335,  0.3518],\n",
      "        [ 0.4495, -0.1138, -0.4219, -0.1152]], requires_grad=True)\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(bika_linear.bias)\n",
    "print(bika_linear.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325f3c88-7bad-4589-b8b9-464f8222af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.,  2., -2.],\n",
      "        [ 2.,  2., -2.],\n",
      "        [ 0.,  2., -2.]], grad_fn=<SumBackward1>)\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor)\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aaa43d-21ca-457a-affd-82b2d289f818",
   "metadata": {},
   "source": [
    "# Try Tiny BiKA with MNIST and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f1b71b-6b55-44a6-b75a-83cc13602bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32827cb-5c2d-4750-82b3-75c0e160c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.MNIST('./data/', \n",
    "                                        train=True, download=True,\n",
    "                                        transform=torchvision.transforms.Compose\n",
    "                                        ([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            #torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                            torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "                                        ]))\n",
    "data_test = torchvision.datasets.MNIST('./data/', \n",
    "                                       train=False, download=True,\n",
    "                                       transform=torchvision.transforms.Compose\n",
    "                                       ([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            #torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                            torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "                                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308351c5-ce72-46d9-ad4e-584dfe360b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size_train = 512\n",
    "batch_size_test = 1000\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size=batch_size_train, \n",
    "                                                shuffle=True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size=batch_size_test, \n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944df90d-dc16-44f2-b3aa-b3c617c00e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -0.9843,  0.6706,  1.0000,  0.1373, -0.8980, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9686,\n",
      "          0.1765,  0.9843,  0.9843,  0.9843, -0.8118, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529,  0.1608,\n",
      "          0.9843,  0.9843,  0.9843,  0.9294, -0.8275, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,  0.9843,\n",
      "          0.9843,  0.9843,  0.9137, -0.3804, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9373,  0.5686,  0.9843,\n",
      "          0.9843,  0.9843,  0.1373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -0.7176,  0.4431,  0.9843,  0.9843,\n",
      "          0.9843,  0.4039, -0.8902, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -0.9294,  0.1765,  0.9843,  0.9843,  0.8824,\n",
      "         -0.1373, -0.8824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -0.4118,  0.9843,  0.9843,  0.9843,  0.2078,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000,  0.3647,  0.9843,  0.9843,  0.8667, -0.6627,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -0.5059,  0.8196,  0.9843,  0.9843, -0.2627, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -0.7725,  0.8275,  0.9843,  0.9843,  0.6157, -0.8824, -1.0000,\n",
      "         -0.8275, -0.1216,  0.5059,  0.5059, -0.5922, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -0.9216,  0.2627,  0.9843,  0.9843,  0.8588, -0.4118, -1.0000, -0.2471,\n",
      "          0.6941,  0.9843,  0.9843,  0.9843,  0.8039, -0.8902, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -0.4431,  0.9843,  0.9843,  0.8588, -0.4196, -1.0000,  0.2157,  0.9059,\n",
      "          0.9843,  0.9843,  0.9843,  0.9843,  0.7255, -0.9059, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9294,\n",
      "          0.4824,  0.9843,  0.9843, -0.2078, -1.0000, -0.2549,  0.9059,  0.9843,\n",
      "          0.9843,  0.9843,  0.9843,  0.9843, -0.1686, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9451,  0.3255,\n",
      "          0.9843,  0.9843,  0.8588, -0.6000, -0.2627,  0.9137,  0.9843,  0.9843,\n",
      "          0.9843,  0.9843,  0.9843,  0.3412, -0.8824, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8510,  0.9843,\n",
      "          0.9843,  0.8745, -0.4745, -0.6549,  0.9216,  0.9843,  0.9843,  0.9843,\n",
      "          0.9843,  0.7176, -0.6235, -0.9686, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4431,  0.9843,\n",
      "          0.9843,  0.8118, -0.1686,  0.5294,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "          0.7255, -0.7098, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7804,  0.9843,\n",
      "          0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.7255,\n",
      "         -0.7176, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8510,  0.9843,\n",
      "          0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.2784, -0.2471,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -0.8588,\n",
      "          0.1294,  0.9843,  0.9843,  0.3176, -0.4588,  0.0118, -0.7490, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(data_loader_train)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data[0][0])\n",
    "example_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b2a95ff-ea7a-4e26-9c24-854d71c77eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fffae836-5a45-4667-a622-b71b7b79eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1*28*28      \n",
    "hidden1 = 256      \n",
    "hidden2 = 256\n",
    "hidden3 = 256\n",
    "num_classes = 10  \n",
    "expand_factor = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e99d4da-52ea-4f61-88a3-6d1915f948c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class BiKA_MNIST(Module):\n",
    "    def __init__(self):\n",
    "        super(BiKA_MNIST, self).__init__()\n",
    "        \n",
    "        self.fc0   = BiKALinear(in_features=input_size, out_features=hidden1, expand_factor=expand_factor)\n",
    "        \n",
    "        self.fc1   = BiKALinear(in_features=hidden1, out_features=hidden2, expand_factor=expand_factor)\n",
    "        \n",
    "        self.fc2   = BiKALinear(in_features=hidden2, out_features=hidden3, expand_factor=expand_factor)\n",
    "        \n",
    "        self.out   = BiKALinear(in_features=hidden3, out_features=num_classes, expand_factor=expand_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        out = self.fc0(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.out(out)\n",
    "        \n",
    "        return out\n",
    "   \n",
    "model = BiKA_MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b349be-f48a-4668-a3e4-0330a4f9b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        inputs, target = data\n",
    "        #inputs, target = inputs.cuda(), target.cuda()\n",
    "        inputs, target = Variable(inputs), Variable(target)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _,pred = torch.max(outputs.data,1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs,target)\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.data.numpy()) \n",
    "           \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98efeebc-78b2-484a-92a8-d54ab7375d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            #inputs, target = inputs.cuda(), target.cuda()\n",
    "            inputs, target = Variable(inputs),Variable(target)\n",
    "            output = model(inputs)\n",
    "            #output = torch.sigmoid(output_orig)  \n",
    "            _,pred = torch.max(output,1)\n",
    "            # compare against a threshold of 0.5 to generate 0/1\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beeb67fa-cc4e-40c2-be6e-47391d8b0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learn_rate = 0.0001 \n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fa929fb-5420-4473-98b5-4feaed3e09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b09afe0-b490-435e-823e-f1e1a7999dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss = 6.615227 test accuracy = 0.835700:  85%|| 17/20 [14:58:47<2:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 29029683955843 is out of bounds for dimension 2 with size 12544",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m t \u001b[38;5;241m=\u001b[39m trange(num_epochs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[0;32m---> 14\u001b[0m         loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         test_acc \u001b[38;5;241m=\u001b[39m test(model, data_loader_test)\n\u001b[1;32m     16\u001b[0m         t\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss = \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m test accuracy = \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(loss_epoch), test_acc))\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs,target)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# keep track of loss value\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Software/Conda_Envs/KAN/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Software/Conda_Envs/KAN/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Software/Conda_Envs/KAN/lib/python3.9/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/Projects/Software/Conda_Envs/KAN/lib/python3.9/site-packages/torch/autograd/function.py:306\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    305\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mCustomSignFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     14\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m grad_output\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Pass the gradient only where input was non-zero, otherwise set it to 0\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mgrad_input\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m grad_output[\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_input\n",
      "\u001b[0;31mIndexError\u001b[0m: index 29029683955843 is out of bounds for dimension 2 with size 12544"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "t = trange(num_epochs, desc=\"Training loss\", leave=True)\n",
    "\n",
    "for epoch in t:\n",
    "        loss_epoch = train(model, data_loader_train, optimizer, criterion)\n",
    "        test_acc = test(model, data_loader_test)\n",
    "        t.set_description(\"Training loss = %f test accuracy = %f\" % (np.mean(loss_epoch), test_acc))\n",
    "        t.refresh() # to show immediately the update           \n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7e524-799e-403d-a9b9-6a4b26fa1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88e03b-ace4-4ae2-965a-8e85106ff5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5648bc9-c478-47d1-ab86-912f11108936",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, data_loader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
