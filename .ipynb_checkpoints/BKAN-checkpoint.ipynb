{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef943b0-76f3-4c9a-856f-705e454c38ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ieyuhaoliu/anaconda3/envs/brevitas/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/ieyuhaoliu/anaconda3/envs/brevitas/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56481973-34cc-49c7-a306-7c7968a35cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.MNIST('./data/', \n",
    "                                        train=True, download=True,\n",
    "                                        transform=torchvision.transforms.Compose\n",
    "                                        ([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "                                        ]))\n",
    "data_test = torchvision.datasets.MNIST('./data/', \n",
    "                                       train=False, download=True,\n",
    "                                       transform=torchvision.transforms.Compose\n",
    "                                       ([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "                                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048dcd99-cad1-4183-a1fe-94f22700e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size=batch_size_train, \n",
    "                                                shuffle=True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size=batch_size_test, \n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1e6118-cefd-4642-b745-353bdb90ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd4a87793b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import brevitas.nn as qnn\n",
    "from brevitas.nn import QuantLinear, QuantReLU, QuantConv2d\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Module\n",
    "from brevitas.quant.binary import SignedBinaryActPerTensorConst\n",
    "from brevitas.quant.binary import SignedBinaryWeightPerTensorConst\n",
    "from brevitas.inject.enum import QuantType\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf319f-65e9-47ea-bbcd-8496c5e70266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051395f5-c2d3-4e62-bb3f-81cc47292754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCV_W1A1(Module):\n",
    "    def __init__(self):\n",
    "        super(TCV_W1A1, self).__init__()\n",
    "        \n",
    "        self.input = qnn.QuantIdentity(\n",
    "                         quant_type='binary',\n",
    "                         scaling_impl_type='const',\n",
    "                         bit_width=act_bit_width,\n",
    "                         min_val=-1.0,\n",
    "                         max_val=1.0, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.conv1 = qnn.QuantConv2d( \n",
    "                         in_channels=in_channels1,\n",
    "                         out_channels=out_channels1,\n",
    "                         kernel_size=kernel_size, \n",
    "                         stride=1, \n",
    "                         padding=1,\n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(out_channels1)\n",
    "        self.relu1 = qnn.QuantReLU(\n",
    "                         bit_width=act_bit_width, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.pool1 = qnn.QuantMaxPool2d(2, return_quant_tensor=True)\n",
    "        \n",
    "        self.conv2 = qnn.QuantConv2d( \n",
    "                         in_channels=in_channels2,\n",
    "                         out_channels=out_channels2,\n",
    "                         kernel_size=kernel_size, \n",
    "                         stride=1, \n",
    "                         padding=1,\n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "        \n",
    "        self.bn2   = nn.BatchNorm2d(out_channels2)\n",
    "        self.relu2 = qnn.QuantReLU(\n",
    "                         bit_width=act_bit_width, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.pool2 = qnn.QuantMaxPool2d(2, return_quant_tensor=True)\n",
    "        \n",
    "        self.fc1   = qnn.QuantLinear(\n",
    "                         input_size, \n",
    "                         hidden1, \n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "        \n",
    "        self.bn3   = nn.BatchNorm1d(hidden1)\n",
    "        self.relu3 = qnn.QuantReLU(\n",
    "                         bit_width=act_bit_width, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.out   = qnn.QuantLinear(\n",
    "                         hidden1, \n",
    "                         num_classes, \n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.input(x)\n",
    "        out = self.pool1(self.relu1(self.bn1(self.conv1(out))))\n",
    "        out = self.pool2(self.relu2(self.bn2(self.conv2(out))))\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.relu3(self.bn3(self.fc1(out)))\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "   \n",
    "model = TCV_W1A1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
